{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST : readFiles\n",
    "\n",
    "Here we execute similar cells as in 1_readFiles, but test out changes when executing cells twice etc.\n",
    "\n",
    "Comparison is mostly done using \n",
    "> assert arr0 == arr0_2test\n",
    "If more calculations are involved and hence small calculation differences, we use the maximal difference.\n",
    "\n",
    "The naming of the second computed values is always appended with \n",
    "> _2test\n",
    "\n",
    "After each comparison the _2test is deleted from the namespace.\n",
    "\n",
    "At the end the namespace is deleted via\n",
    "> %reset -f\n",
    "to clear up space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/Users/janfelixsenge\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change current working directory to parent folder, to execute script as if we execute ther\n",
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches  # for plotSubregions\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# import path variables\n",
    "from src.config import data_path_raw_simulation, data_path_interim\n",
    "# import the read and check method files\n",
    "from src.preprocess.read_simulation_files import (\n",
    "    read_heightmaps_sequences, check_if_regulargrid,\n",
    "    interpolate_grid, interpolate_regular_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and inteprolate\n",
    "\n",
    "Read numerical Simulation csv-files and interpolate them on a regular grid for different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read\n",
    "\n",
    "Read the csv files in the dir_read_path and create lists of z-values, \n",
    "x-values and y-values as well as a dataframe grabbing the coverage \n",
    "class, sequence number as well as number of impacts from the filenames.\n",
    "\n",
    "Since the coverage classes are not representative of the actual coverage values they will be replaced later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files for the different files for the numerical simulation\n",
    "z, x, y, df_info = read_heightmaps_sequences(data_path_raw_simulation,\n",
    "                                             z_name='U3',\n",
    "                                             x_name='x',\n",
    "                                             y_name='y')\n",
    "\n",
    "z_2test, x_2test, y_2test, df_info_2test = read_heightmaps_sequences(data_path_raw_simulation,\n",
    "                                             z_name='U3',\n",
    "                                             x_name='x',\n",
    "                                             y_name='y')\n",
    "\n",
    "assert (z==z_2test).all()\n",
    "assert (x==x_2test).all()\n",
    "assert (y==y_2test).all()\n",
    "assert (df_info == df_info_2test).all().all()\n",
    "\n",
    "# change the coverage values contained in the filenames of the\n",
    "# heightmap to have it for later\n",
    "df_info['coverage_old'] = df_info['coverage'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate to get regular grid\n",
    "\n",
    "Compare the regular grid interpolations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a interpolation size so that we are close to the grid values of the \n",
    "# original 74x74 grids. Using np.linspace in interpolate_regular_grid, \n",
    "# the intrpolation_size giving the same grid values for an evenly spaced\n",
    "# regular grid, is:\n",
    "interpolation_size = 1+73*14\n",
    "znew, xnew, ynew = interpolate_regular_grid(z, x, y, \n",
    "                                            interpolation_size, \n",
    "                                            bigger_grid=False)\n",
    "\n",
    "znew_2test, xnew_2test, ynew_2test = interpolate_regular_grid(z, x, y, \n",
    "                                            interpolation_size, \n",
    "                                            bigger_grid=False)\n",
    "\n",
    "assert (znew==znew_2test).all()\n",
    "assert (xnew==xnew_2test).all()\n",
    "assert (ynew==ynew_2test).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the coverage values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data, get the according values and delete the loaded data again\n",
    "data = np.load(data_path_interim / 'surface_numSimulation.npz')\n",
    "znew = data['values']\n",
    "xnew = data['x_grid']\n",
    "ynew = data['y_grid']\n",
    "\n",
    "df_info = pd.read_csv(data_path_interim / 'surface_numSimulation_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.approximate_coverage import get_local_minima\n",
    "\n",
    "# size of the indent circles and the larger circle\n",
    "radius_indent = 0.055/2\n",
    "radius_circ = 0.2/2\n",
    "\n",
    "# important to guaranteu that certain points can be a little bit closer than the complete circle\n",
    "eps = 0.005\n",
    "\n",
    "minima_arr = get_local_minima(z=znew,\n",
    "                              grid=xnew,\n",
    "                              radius_indent=radius_indent,\n",
    "                              eps=eps,\n",
    "                              df_info=df_info)\n",
    "\n",
    "minima_arr_2test = get_local_minima(z=znew,\n",
    "                                    grid=xnew,\n",
    "                                    radius_indent=radius_indent,\n",
    "                                    eps=eps,\n",
    "                                    df_info=df_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the np.nan values inside the arrays by unstacking them and sorting them (to account for different order in the method). \n",
    "\n",
    "unstack --> list of numpy arrays of different size (ni,2).\n",
    "\n",
    "Then compare them by comparing each of the list elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstack = [minima_arr[i][~np.isnan(minima_arr[i][:, 0]), :].astype('int')\n",
    "           for i in range(minima_arr.shape[0])]\n",
    "unstack = [unstack[i][np.argsort(unstack[i][:, 0])]\n",
    "           for i in range(len(unstack))]\n",
    "\n",
    "unstack_2test = [minima_arr_2test[i][~np.isnan(minima_arr_2test[i][:, 0]), :].astype('int')\n",
    "                 for i in range(minima_arr_2test.shape[0])]\n",
    "unstack_2test = [unstack_2test[i][np.argsort(unstack_2test[i][:, 0])]\n",
    "                 for i in range(len(unstack_2test))]\n",
    "\n",
    "\n",
    "# check if they are the same\n",
    "assert len(unstack) == len(unstack_2test)\n",
    "tmp_2test = np.array([(unstack[i]==unstack_2test[i]).all()\n",
    "                      for i in range(len(unstack))])\n",
    "assert tmp_2test.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now check the masks and the coverage values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.approximate_coverage import approximate_coverage\n",
    "\n",
    "coverage_list, mask_list =\\\n",
    "    approximate_coverage(minima_arr=minima_arr,\n",
    "                         xgrid=xnew,\n",
    "                         ygrid=ynew,\n",
    "                         radius_circ=radius_circ, \n",
    "                         radius_indent=radius_indent,\n",
    "                         df_info=df_info)\n",
    "    \n",
    "coverage_list_2test, mask_list_2test =\\\n",
    "    approximate_coverage(minima_arr=minima_arr,\n",
    "                         xgrid=xnew,\n",
    "                         ygrid=ynew,\n",
    "                         radius_circ=radius_circ, \n",
    "                         radius_indent=radius_indent,\n",
    "                         df_info=df_info)\n",
    "    \n",
    "# check: convert to numpy arrays and check all entries\n",
    "assert (np.array(coverage_list) == np.array(coverage_list_2test)).all()\n",
    "assert (np.array(mask_list) == np.array(mask_list_2test)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset complete namespace\n",
    "\n",
    "So that the jupyter notebook doesn't clutter anything, we delete it's namespace in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "498cefaf8d0898ee928794f48868e4ec654a1cb58f358fafec9e4a92fd13f5d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shotpeening': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
